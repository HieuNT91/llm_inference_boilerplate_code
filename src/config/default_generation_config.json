{
    "attention_implementation": "flash_attention_2", 
    "max_new_tokens": 700,
    "temperature": 1,
    "top_k": 50,
    "top_p": 1.0,
    "repetition_penalty": 1.0,
    "num_return_sequences": 5,
    "use_cache": true,
    "do_sample": true
}