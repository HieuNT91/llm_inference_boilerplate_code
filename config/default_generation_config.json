{
    "attention_implementation": "flash_attention_2", 
    "max_new_tokens": 2048,
    "temperature": 0.9,
    "top_k": 50,
    "top_p": 1.0,
    "repetition_penalty": 1.0,
    "num_return_sequences": 4,
    "use_cache": true,
    "do_sample": true,
    "cache_interval": 4, 
    "batch_size_per_device": 4
}